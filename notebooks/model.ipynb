{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import laspy as lp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def read_las_file(las_path):\n",
    "    try:\n",
    "        return lp.read(las_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {las_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def normalize_colors(colors):\n",
    "    rgba = colors - colors.min(axis=0)\n",
    "    rgba = rgba / rgba.max(axis=0)\n",
    "    return (rgba * 255).astype(np.uint8)\n",
    "\n",
    "def normalize_points(points, eps= 1e-8):\n",
    "    if not isinstance(points, np.ndarray) or points.shape[1] != 3:\n",
    "        raise ValueError(\"points must be a numpy array with shape (n, 3).\")\n",
    "    points_ = points.copy()\n",
    "\n",
    "    x_min, x_max = np.min(points_[:,0]), np.max(points_[:,0])\n",
    "    y_min, y_max = np.min(points_[:,1]), np.max(points_[:,1])\n",
    "    z_min, z_max = np.min(points_[:,2]), np.max(points_[:,2])\n",
    "\n",
    "    points_[:,0] = (points_[:,0] - x_min) / (x_max - x_min + eps)\n",
    "    points_[:,1] = (points_[:,1] - y_min) / (y_max - y_min + eps)\n",
    "    points_[:,2] = (points_[:,2] - z_min) / (z_max - z_min + eps)\n",
    "    \n",
    "    return points_, x_min, x_max, y_min, y_max, z_min, z_max  \n",
    "\n",
    "def get_points_and_colors(las_paths: list, limit: int = -1):\n",
    "    if not isinstance(las_paths, list) or not all(isinstance(path, str) for path in las_paths):\n",
    "        raise ValueError(\"las_paths must be a list of strings.\")\n",
    "\n",
    "    if not isinstance(limit, int) or limit < -1:\n",
    "        raise ValueError(\"limit must be an integer greater than or equal to -1.\")\n",
    "\n",
    "    points = []\n",
    "    colors = []\n",
    "    classes = []\n",
    "\n",
    "    for las_path in las_paths:\n",
    "        las = read_las_file(las_path)\n",
    "        if las is not None:\n",
    "            points.append(np.vstack((las.x, las.y, las.z)).transpose())\n",
    "            colors.append(np.vstack((las.red, las.green, las.blue)).transpose())\n",
    "            classes.append(las.classification)\n",
    "\n",
    "    if not points:\n",
    "        raise ValueError(\"No valid LAS files found.\")\n",
    "\n",
    "    points = np.vstack(points)\n",
    "    colors = np.vstack(colors)\n",
    "    classes = np.hstack(classes)\n",
    "\n",
    "    if limit > 0:\n",
    "        idxs = np.random.choice(len(points), limit, replace=False)\n",
    "        points = points[idxs]\n",
    "        colors = colors[idxs]\n",
    "        classes = classes[idxs]\n",
    "\n",
    "    rgba_colors = normalize_colors(colors)\n",
    "\n",
    "    return points, colors, rgba_colors, classes\n",
    "\n",
    "\n",
    "def get_neighborhood(kdtree, point_idx, radius):\n",
    "    indices = kdtree.query_radius([kdtree.data[point_idx]], r=radius)\n",
    "    return indices[0]\n",
    "\n",
    "def automatic_gmm_components(data, max_components=2, criterion='aic', T=0.1, **kwargs):\n",
    "    n_components_range = range(1, max_components + 1)\n",
    "    criterions, means = [], []\n",
    "    if criterion not in ['aic', 'bic']:\n",
    "        raise ValueError(\"Criterio no válido. Usa 'bic' o 'aic'.\")\n",
    "    \n",
    "    for n in n_components_range:\n",
    "        try:\n",
    "            gmm = GaussianMixture(n_components=n, **kwargs)\n",
    "            gmm.fit(data)\n",
    "            criterions.append(gmm.bic(data)) if criterion == 'bic' else criterions.append(gmm.aic(data))\n",
    "            means.append(gmm.means_)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Error fitting GMM with {n} components: {e}\")\n",
    "            break\n",
    "\n",
    "    optimal_idx = np.argmin(criterions)\n",
    "    optimal_means = means[optimal_idx]\n",
    "    optimal_components = n_components_range[optimal_idx]\n",
    "    \n",
    "    if optimal_components == 2 and abs(optimal_means[0] - optimal_means[1]) <= T:\n",
    "        return 1, [np.mean(optimal_means, dtype=np.float32)]\n",
    "    \n",
    "    if not criterions:\n",
    "        return 1, [np.mean(data, dtype=np.float32)]  # Si no se pudo ajustar ningún modelo, devolver 1 componente\n",
    "    \n",
    "    return optimal_components, means[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 3), (10000, 3), (10000, 3), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_project = 'poza1b'\n",
    "path_project = f'../data/{name_project}' \n",
    "\n",
    "las_paths = [f'{path_project}/{filename}' for filename in os.listdir(path_project) if filename.endswith('.las')]\n",
    "points, colors, rgba_colors, classes = get_points_and_colors(las_paths, limit=10_000)\n",
    "\n",
    "points.shape, colors.shape, rgba_colors.shape, classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definir el tamaño de la vecindad\n",
    "# result = []\n",
    "# neighborhood_size = 10 # transforma a metro \n",
    "# x,y,z = points[:,0], points[:,1], points[:,2]\n",
    "\n",
    "# points_norm, x_min, x_max, y_min,y_max, z_min, z_max = normalize_points(points)\n",
    "# x_norm,y_norm,z_norm = points_norm[:,0], points_norm[:,1], points_norm[:,2]\n",
    "\n",
    "# neighborhood_size_x = neighborhood_size / (x_max - x_min + 1e-8)\n",
    "# neighborhood_size_y = neighborhood_size / (y_max - y_min + 1e-8)\n",
    "\n",
    "# # Iterar sobre cada punto (x, y)\n",
    "# for i in tqdm(range(len(x))):\n",
    "#     # Filtrar los puntos en la vecindad\n",
    "#     px, py, pz = x_norm[i], y_norm[i], z_norm[i] \n",
    "#     ## obtener todo los puntos de la venciddad de px py utlizar kdtree para la vencidad\n",
    "#     mask = (np.abs(x_norm - px) < neighborhood_size_x) & (np.abs(y_norm - py) < neighborhood_size_y)\n",
    "#     z_neighborhood = z_norm[mask]\n",
    "\n",
    "#     if len(z_neighborhood) < 2:\n",
    "#         continue\n",
    "\n",
    "#     z_neighborhood = z_neighborhood.reshape(-1, 1)\n",
    "\n",
    "#     # Encontrar y ajustar el modelo óptimo\n",
    "#     optimal_n_components, means = automatic_gmm_components(z_neighborhood, max_components=2)\n",
    "#     result.append([x_norm[i], y_norm[i], z_norm[i], optimal_n_components])\n",
    "\n",
    "#     # if optimal_n_components >= 2:\n",
    "\n",
    "#     #     gmm_optimal = GaussianMixture(n_components=optimal_n_components, random_state=42)\n",
    "#     #     gmm_optimal.fit(z_neighborhood)\n",
    "\n",
    "#     #     # Preparar datos para la gráfica\n",
    "#     #     x_min_, x_max_ = z_neighborhood.min() - 1, z_neighborhood.max() + 1\n",
    "#     #     x_axis = np.linspace(x_min_, x_max_, 1000).reshape(-1, 1)\n",
    "        \n",
    "#     #     # Calcular componentes\n",
    "#     #     logprob = gmm_optimal.score_samples(x_axis)\n",
    "#     #     individual_pdfs = np.exp(gmm_optimal.score_samples(x_axis))  # PDF de la mezcla completa\n",
    "\n",
    "#     #     # Configurar la gráfica\n",
    "#     #     plt.figure(figsize=(10, 6))\n",
    "#     #     plt.hist(z_neighborhood, bins=30, density=True, alpha=0.6, color='g', label='Datos')\n",
    "#     #     plt.plot(x_axis, np.exp(logprob), 'k-', lw=2, label='Mezcla GMM')\n",
    "\n",
    "#     #     # Graficar componentes individuales\n",
    "#     #     for j in range(gmm_optimal.n_components):\n",
    "#     #         weight = gmm_optimal.weights_[j]\n",
    "#     #         mean = gmm_optimal.means_[j, 0]\n",
    "#     #         std = np.sqrt(gmm_optimal.covariances_[j, 0])\n",
    "            \n",
    "#     #         component_pdf = weight * (1/(std * np.sqrt(2 * np.pi))) * \\\n",
    "#     #                     np.exp(-0.5 * ((x_axis - mean)/std)**2)\n",
    "            \n",
    "#     #         plt.plot(x_axis, component_pdf, '--', lw=2, \n",
    "#     #                 label='ac') #f'Componente {j+1} ($\\mu$={mean:.2f}, $\\sigma$={std:.2f})')\n",
    "#     #     plt.title(f'Distribución de z en ({x_norm[i]:.2f}, {y_norm[i]:.2f}) - {optimal_n_components} componentes')\n",
    "#     #     plt.xlabel('Valor de z')\n",
    "#     #     plt.ylabel('Frecuencia')\n",
    "#     #     plt.legend()\n",
    "#     #     plt.show()\n",
    "\n",
    "# np.array(result).shape         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 4169/10000 [00:02<00:03, 1673.71it/s]/home/yeriel/workspace/kauel/sqm_batimetria/notebooks/env/lib/python3.12/site-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      " 70%|███████   | 7033/10000 [00:04<00:01, 1643.29it/s]/home/yeriel/workspace/kauel/sqm_batimetria/notebooks/env/lib/python3.12/site-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      " 73%|███████▎  | 7252/10000 [00:04<00:01, 1780.63it/s]/home/yeriel/workspace/kauel/sqm_batimetria/notebooks/env/lib/python3.12/site-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      " 86%|████████▋ | 8629/10000 [00:05<00:00, 1717.35it/s]/home/yeriel/workspace/kauel/sqm_batimetria/notebooks/env/lib/python3.12/site-packages/sklearn/base.py:1389: ConvergenceWarning: Number of distinct clusters (1) found smaller than n_clusters (2). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "100%|██████████| 10000/10000 [00:05<00:00, 1693.63it/s]\n"
     ]
    }
   ],
   "source": [
    "neighborhood_size = 1\n",
    "x, y, z = points[:, 0], points[:, 1], points[:, 2]\n",
    "\n",
    "points_norm, x_min, x_max, y_min, y_max, z_min, z_max = normalize_points(points)\n",
    "x_norm, y_norm, z_norm = points_norm[:, 0], points_norm[:, 1], points_norm[:, 2]\n",
    "\n",
    "neighborhood_size_x = neighborhood_size / (x_max - x_min + 1e-8)\n",
    "neighborhood_size_y = neighborhood_size / (y_max - y_min + 1e-8)\n",
    "\n",
    "kdtree = KDTree(points_norm[:, :2])  # Solo usamos x y para calcular la vecindad\n",
    "result = []\n",
    "\n",
    "for i in tqdm(range(len(x_norm))):\n",
    "    px, py = x_norm[i], y_norm[i]\n",
    "    \n",
    "    # Obtener los índices de los puntos en la vecindad usando KDTree\n",
    "    indices_neighborhood = get_neighborhood(kdtree, i, neighborhood_size_x)\n",
    "    \n",
    "    # Filtrar los puntos en la vecindad por las coordenadas Y\n",
    "    #mask_y = np.abs(y_norm[indices_neighborhood] - py) < neighborhood_size_y\n",
    "    #indices_neighborhood = indices_neighborhood[mask_y]\n",
    "    \n",
    "    z_neighborhood = z_norm[indices_neighborhood]\n",
    "    \n",
    "    if len(z_neighborhood) < 2:\n",
    "        continue\n",
    "    \n",
    "    z_neighborhood = z_neighborhood.reshape(-1, 1)\n",
    "    optimal_n_components, means = automatic_gmm_components(z_neighborhood, max_components=2)\n",
    "    result.append([x_norm[i], y_norm[i], z_norm[i], optimal_n_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1103, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(result).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
