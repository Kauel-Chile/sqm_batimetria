{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from pathlib import Path\n",
    "\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "class CoordinateDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data = pd.read_csv(data_dir)\n",
    "        self.x, self.y = self.__processing()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx] # Se regresa un registro de datos junto con su etiqueta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __processing(self):\n",
    "        i, o = self.data[['x', 'y']].to_numpy(), self.data[['z','red', 'green', 'blue']].to_numpy()\n",
    "        return torch.from_numpy(i).float(), torch.from_numpy(o).float()  \n",
    "\n",
    "PATH_DATASET = 'pool_data_pool_surface.csv'\n",
    "dataset = CoordinateDataset(PATH_DATASET)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "ROPE_DIM = 128   # Dimension for each coordinate's RoPE embedding\n",
    "LINEAR_DIM = 256 # Dimension for each linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imagenp_open_img(filename:str,BGR2RGB:bool=True) -> np.array:\n",
    "#     \"\"\" Abre una imagen desde un archivo. Soporta caracteres internacionales \"\"\"\n",
    "#     f=open(filename,'rb')\n",
    "#     data=f.read()\n",
    "#     f.close()\n",
    "#     data = np.frombuffer(data, np.uint8)\n",
    "#     img = cv2.imdecode(data,flags=cv2.IMREAD_COLOR)\n",
    "#     if(BGR2RGB): img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "#     return img\n",
    "\n",
    "# def imagenp_show_image(img, figsize=(6,6),title='',normalize01=False, cmap=None):\n",
    "#     '''Muestra una imagen.\n",
    "#     image = show_image('../misc/panda.jpg',(15,15))\n",
    "\n",
    "#     Args:\n",
    "#         img (str|np.ndarray|PIL.Image.Image): La imagen o ruta del archivo\n",
    "#         figsize (int,int): Dimensiones de la figura de matplotlib.pyplot\n",
    "#         title (str): Titulo de la imagen\n",
    "#         normalize01: Normaliza los datos en el rango [0.0 1.0]\n",
    "#         cmap: 'gray', 'gray_r', 'Accent', 'Blues', 'BrBG', 'BuGn', 'BuPu', 'CMRmap', 'Dark2', 'GnBu', 'Greens', 'Greys', 'OrRd', 'Oranges', 'PRGn', 'Paired', 'Pastel1', 'Pastel2', 'PiYG', 'PuBu', 'PuBuGn', 'PuOr', 'PuRd', 'Purples', 'RdBu', 'RdGy', 'RdPu', 'RdYlBu', 'RdYlGn', 'Reds', 'Set1', 'Set2', 'Set3', 'Spectral', 'Wistia', 'YlGn', 'YlGnBu', 'YlOrBr', 'YlOrRd', 'afmhot', 'autumn', 'binary', 'bone', 'brg', 'bwr', 'cool', 'coolwarm', 'copper', 'cubehelix', 'flag', 'gist_earth', 'gist_gray', 'gist_heat', 'gist_ncar', 'gist_rainbow', 'gist_stern', 'gist_yarg', 'gnuplot', 'gnuplot2', 'gray', 'hot', 'hsv', 'jet', 'nipy_spectral', 'ocean', 'pink', 'prism', 'rainbow', 'seismic', 'spring', 'summer', 'tab10', 'tab20', 'tab20b', 'tab20c', 'terrain', 'winter'\n",
    "#     '''\n",
    "#     if isinstance(img,(str|Path)):\n",
    "#         if not title: title = str(img)\n",
    "#         img = imagenp_open_img(img,BGR2RGB=True)\n",
    "\n",
    "#     # if isinstance(img,(PIL.Image.Image)): img = np.array(img)\n",
    "        \n",
    "#     original_shape = img.shape\n",
    "#     original_dtype = img.dtype\n",
    "#     mini = np.min(img)\n",
    "#     maxi = np.max(img)\n",
    "        \n",
    "#     if img.shape[-1]<3:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "#     # if len(img.shape)==4: img = imagenp_grid_images(img)\n",
    "        \n",
    "#     if normalize01 and maxi > mini: img = (img-mini)/(maxi-mini)\n",
    "    \n",
    "#     plt.figure(figsize=figsize)\n",
    "#     title += f\" {original_shape} {original_dtype} {mini:.1f} {maxi:.1f}\"\n",
    "#     plt.title(title)\n",
    "#     plt.imshow(img, cmap=cmap)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "    \n",
    "# def imagenp_save_image(filename,img, flipBR=True):\n",
    "#     '''Guarda una imagen en disco.\n",
    "#     save_image(img, '../misc/panda.jpg')\n",
    "#     Args:\n",
    "#         filename (str): Nombre del archivo donde guardar la imagen\n",
    "#         img (np.ndarray): La imagen.\n",
    "#     '''\n",
    "#     if(flipBR) and (img.shape[-1]==3): img=cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "#     cv2.imwrite(filename,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_module_parameters(module):\n",
    "    \"\"\" Retorna la cantidad de parametros del modulo pytorch \"\"\"\n",
    "    pp=0\n",
    "    for p in list(module.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_image = imagenp_open_img(\"escultura.jpg\")\n",
    "# imagenp_show_image(dataset_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataset and dataloader\n",
    "# class CoordinateDataset(Dataset):\n",
    "#     def __init__(self, image=None):\n",
    "#         self.height, self.width, _ = (2048,2048,3) if image is None else image.shape #Si image is None, retorna coordenadas de una imagen de 2048x2048x3\n",
    "#         x_coords = torch.linspace(0, 1, self.width)\n",
    "#         y_coords = torch.linspace(0, 1, self.height)\n",
    "#         x_grid, y_grid = torch.meshgrid(x_coords, y_coords, indexing='xy')        \n",
    "#         self.coords = torch.stack([x_grid.ravel(), y_grid.ravel()], dim=1)\n",
    "#         self.rgb = None if image is None else torch.from_numpy(image).float().view(-1, 3)/255\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.coords)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if self.rgb is None: return self.coords[idx] #Retorna solo coordenadas\n",
    "#         return self.coords[idx], self.rgb[idx] #Retorna coordenadas e imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = CoordinateDataset(dataset_image)\n",
    "# dataloader  = DataLoader(dataset,             batch_size=BATCH_SIZE, shuffle=True)   #Coordenadas desordenadas para entrenamiento\n",
    "# dataloader2 = DataLoader(dataset,             batch_size=BATCH_SIZE, shuffle=False)  #Coordenadas ordenadas para evaluacion\n",
    "# dataloader3 = DataLoader(CoordinateDataset(), batch_size=BATCH_SIZE, shuffle=False)  #Coordenadas ordenadas para upsampling 2048x2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotary Position Embedding (RoPE) module\n",
    "class RoPE(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        inv_freq = torch.logspace(0, 3, dim//2) #Valores que multiplican al angulo van desde 1 a 1000 en escala logaritmica\n",
    "        self.register_buffer('inv_freq', inv_freq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 2) containing (x, y) coordinates\n",
    "        x_coords = x[:, 0]\n",
    "        y_coords = x[:, 1]\n",
    "        \n",
    "        x_embed = self._embed_single(x_coords)\n",
    "        y_embed = self._embed_single(y_coords)\n",
    "        return torch.cat([x_embed, y_embed], dim=1)\n",
    "\n",
    "    def _embed_single(self, pos):\n",
    "        # pos shape: (batch_size,)\n",
    "        angles = pos.unsqueeze(-1) * self.inv_freq.unsqueeze(0)\n",
    "        sin = torch.sin(angles)\n",
    "        cos = torch.cos(angles)\n",
    "        \n",
    "        # Interleave sin and cos values\n",
    "        embed = torch.stack([sin, cos], dim=-1)\n",
    "        return embed.view(embed.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "class ColorNetRope(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rope = RoPE(ROPE_DIM)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(2 * ROPE_DIM, LINEAR_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(LINEAR_DIM, LINEAR_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(LINEAR_DIM, LINEAR_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(LINEAR_DIM, 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rope(x)\n",
    "        return self.layers(x)\n",
    "    \n",
    "# # Neural network architecture\n",
    "# class ColorNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layers = nn.Sequential(\n",
    "#             nn.Linear(2, LINEAR_DIM),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(LINEAR_DIM, LINEAR_DIM),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(LINEAR_DIM, LINEAR_DIM),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(LINEAR_DIM, 3),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 198404\n"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model = ColorNet().to(device)\n",
    "model = ColorNetRope().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=LEARNING_RATE*0.1)\n",
    "\n",
    "print(f\"Model Parameters: {pt_module_parameters(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss = []\n",
    "# for epoch in range(EPOCHS):\n",
    "#     epoch_loss = 0.0\n",
    "#     for inputs, targets in dataloader:\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "#     scheduler.step()\n",
    "#     epoch_loss /= len(dataset)\n",
    "#     train_loss.append(epoch_loss)\n",
    "#     print(f'Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss:.6f} LR: {scheduler.get_last_lr()[0]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:  18%|█▊        | 5237/29389 [00:45<03:56, 102.24it/s, loss=22059.5, lr=0.001]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{EPOCHS}', leave=False)\n",
    "    for inputs, targets in progress_bar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "        progress_bar.set_postfix(loss=loss.item(), lr=scheduler.get_last_lr()[0])\n",
    "    scheduler.step()\n",
    "    epoch_loss /= len(dataset)\n",
    "    train_loss.append(epoch_loss)\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss:.6f} LR: {scheduler.get_last_lr()[0]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_loss)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final metrics\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "    \n",
    "    for inputs, targets in dataloader2:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        all_outputs.append(outputs.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "    \n",
    "    outputs = torch.cat(all_outputs)\n",
    "    targets = torch.cat(all_targets)\n",
    "    \n",
    "    # Calculate MSE and PSNR\n",
    "    mse = criterion(outputs, targets)\n",
    "    psnr = 20 * torch.log10(torch.tensor(1.0)) - 10 * torch.log10(mse)\n",
    "    \n",
    "    print(f'\\nFinal Metrics:')\n",
    "    print(f'MSE: {mse.item():.6f}')\n",
    "    print(f'PSNR: {psnr.item():.2f} dB')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "with torch.no_grad():\n",
    "    predicted_image = outputs.view(dataset_image.shape[-3], dataset_image.shape[-2], dataset_image.shape[-1]).numpy()\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(dataset_image)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].imshow(predicted_image)\n",
    "ax[1].set_title('Predicted Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final metrics\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_2k = []\n",
    "    \n",
    "    for inputs in dataloader3:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        all_2k.append(outputs.cpu())\n",
    "    \n",
    "    outputs = torch.cat(all_2k)\n",
    "    predicted_image = outputs.view(2048, 2048, 3).numpy()\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(dataset_image)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[1].imshow(predicted_image)\n",
    "ax[1].set_title('Upscaled Image')\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenp_save_image(\"output02.jpg\", (predicted_image*255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
